{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in ./myenv/lib/python3.9/site-packages (0.3.15)\n",
      "Requirement already satisfied: langchain-core in ./myenv/lib/python3.9/site-packages (0.3.31)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./myenv/lib/python3.9/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./myenv/lib/python3.9/site-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./myenv/lib/python3.9/site-packages (from langchain-community) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./myenv/lib/python3.9/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in ./myenv/lib/python3.9/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.15 in ./myenv/lib/python3.9/site-packages (from langchain-community) (0.3.15)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./myenv/lib/python3.9/site-packages (from langchain-community) (0.3.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./myenv/lib/python3.9/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./myenv/lib/python3.9/site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in ./myenv/lib/python3.9/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./myenv/lib/python3.9/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./myenv/lib/python3.9/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./myenv/lib/python3.9/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./myenv/lib/python3.9/site-packages (from langchain-core) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./myenv/lib/python3.9/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./myenv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./myenv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./myenv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./myenv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in ./myenv/lib/python3.9/site-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./myenv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./myenv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./myenv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./myenv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./myenv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./myenv/lib/python3.9/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: anyio in ./myenv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./myenv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./myenv/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./myenv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./myenv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-community langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import rdflib\n",
    "\n",
    "from typing import List\n",
    "from langchain_community.graphs import OntotextGraphDBGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fix Langchain OntotextGraphDBGraph\n",
    "\n",
    "- OntotextGraphDBGraph does not support ASK query type and always return []\n",
    "- Fixed to return Yes/No\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOntotextGraphDBGraph(OntotextGraphDBGraph):\n",
    "    def __init__(self, query_endpoint: str, schema: str) -> None:\n",
    "        try:\n",
    "            import rdflib\n",
    "            from rdflib.plugins.stores import sparqlstore\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import rdflib python package. \"\n",
    "                \"Please install it with `pip install rdflib`.\"\n",
    "            )\n",
    "\n",
    "        auth = self._get_auth()\n",
    "        store = sparqlstore.SPARQLStore(auth=auth)\n",
    "        store.open(query_endpoint)\n",
    "\n",
    "        self.graph = rdflib.Graph(store, identifier=None, bind_namespaces=\"none\")\n",
    "        self._check_connectivity()\n",
    "        if not os.path.exists(schema):\n",
    "            raise FileNotFoundError(f\"File {schema} does not exist.\")\n",
    "        with open(schema, \"r\") as file:\n",
    "            schema_string = file.readlines()\n",
    "        self.schema = schema_string\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        query: str,\n",
    "    ) -> List[rdflib.query.ResultRow]:\n",
    "        \"\"\"\n",
    "        Query the graph.\n",
    "        \"\"\"\n",
    "        from rdflib.query import ResultRow\n",
    "\n",
    "        res = self.graph.query(query)\n",
    "        if res.type == \"ASK\":\n",
    "            return [r for r in res if isinstance(r, bool)]\n",
    "        return [r for r in res if isinstance(r, ResultRow)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading GraphDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"query_endpoint\": \"http://localhost:7200/repositories/imkg\",\n",
    "    \"schema\": \"/Users/jerry/Desktop/FYP-working/fine-tune-openai-KGQA/KG/schema.txt\",\n",
    "}\n",
    "graph = CustomOntotextGraphDBGraph(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Calculate metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counts\n",
    "def calculate_metrics(results):\n",
    "    query_level = {\n",
    "        \"TP\": 0,  # True Positives\n",
    "        \"FN\": 0,  # False Positives\n",
    "        \"FP\": 0,  # Always 0 because query is always expecting correct results\n",
    "        \"TN\": 0,  # Always 0 because query is always expecting correct results\n",
    "    }\n",
    "    item_level = {\n",
    "        \"TP\": 0,  # True Positives\n",
    "        \"FN\": 0,  # In sparql_response, but in sample_query\n",
    "        \"FP\": 0,  # In sample_query, but in sparql_response\n",
    "        \"TN\": 0,  # Always 0 because query is always expecting correct results\n",
    "    }\n",
    "\n",
    "    for data_point in results:\n",
    "        sparql_response = data_point.get(\"sparql_response\") or data_point.get(\n",
    "            \"generated_sparql\"\n",
    "        )  # Model-generated query\n",
    "        sample_query = data_point.get(\"sparql\")  # Ground-truth query\n",
    "\n",
    "        if sparql_response and sample_query:\n",
    "            try:\n",
    "                generated_results = set(graph.query(sparql_response))\n",
    "                sample_results = set(graph.query(sample_query))\n",
    "\n",
    "                if generated_results == sample_results:\n",
    "                    query_level[\"TP\"] += 1\n",
    "                else:\n",
    "                    query_level[\"FN\"] += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                generated_results = set()\n",
    "                error_message = str(e).lower()\n",
    "                print(error_message)\n",
    "                query_level[\"FN\"] += 1\n",
    "        item_level[\"TP\"] += len(generated_results & sample_results)\n",
    "        item_level[\"FN\"] += len(sample_results - generated_results)\n",
    "        item_level[\"FP\"] += len(generated_results - sample_results)\n",
    "    # Compute accuracy\n",
    "    query_level_total_samples = sum(query_level.values())\n",
    "    query_level_accuracy = (\n",
    "        (query_level[\"TP\"] + query_level[\"TN\"]) / query_level_total_samples\n",
    "        if query_level_total_samples\n",
    "        else 0\n",
    "    )\n",
    "    query_level_precision = (\n",
    "        query_level[\"TP\"] / (query_level[\"TP\"] + query_level[\"FP\"])\n",
    "        if (query_level[\"TP\"] + query_level[\"FP\"])\n",
    "        else 0\n",
    "    )\n",
    "    query_level_recall = (\n",
    "        query_level[\"TP\"] / (query_level[\"TP\"] + query_level[\"FN\"])\n",
    "        if (query_level[\"TP\"] + query_level[\"FN\"])\n",
    "        else 0\n",
    "    )\n",
    "    query_level_results = {\n",
    "        \"accuracy\": query_level_accuracy,\n",
    "        \"precision\": query_level_precision,\n",
    "        \"recall\": query_level_recall,\n",
    "        \"f1_score\": (\n",
    "            2\n",
    "            * (query_level_precision * query_level_recall)\n",
    "            / (query_level_precision + query_level_recall)\n",
    "            if (query_level_precision + query_level_recall)\n",
    "            else 0\n",
    "        ),\n",
    "    }\n",
    "    item_level_total_samples = sum(item_level.values())\n",
    "    item_level_accuracy = (\n",
    "        (item_level[\"TP\"] + item_level[\"TN\"]) / item_level_total_samples\n",
    "        if item_level_total_samples\n",
    "        else 0\n",
    "    )\n",
    "    item_level_precision = (\n",
    "        item_level[\"TP\"] / (item_level[\"TP\"] + item_level[\"FP\"])\n",
    "        if (item_level[\"TP\"] + item_level[\"FP\"])\n",
    "        else 0\n",
    "    )\n",
    "    item_level_recall = (\n",
    "        item_level[\"TP\"] / (item_level[\"TP\"] + item_level[\"FN\"])\n",
    "        if (item_level[\"TP\"] + item_level[\"FN\"])\n",
    "        else 0\n",
    "    )\n",
    "    item_level_results = {\n",
    "        \"accuracy\": item_level_accuracy,\n",
    "        \"precision\": item_level_precision,\n",
    "        \"recall\": item_level_recall,\n",
    "        \"f1_score\": (\n",
    "            2\n",
    "            * (item_level_precision * item_level_recall)\n",
    "            / (item_level_precision + item_level_recall)\n",
    "            if (item_level_precision + item_level_recall)\n",
    "            else 0\n",
    "        ),\n",
    "    }\n",
    "    return query_level_results, item_level_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Measure metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you did something wrong formulating either the uri or your sparql query\n",
      "GPT4O metrics:\n",
      "Query Level Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.8962264150943396,\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.8962264150943396,\n",
      "    \"f1_score\": 0.9452736318407959\n",
      "}\n",
      "Item Level Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.8105849582172702,\n",
      "    \"precision\": 0.9765100671140939,\n",
      "    \"recall\": 0.8267045454545454,\n",
      "    \"f1_score\": 0.8953846153846152\n",
      "}\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "QWEN metrics:\n",
      "Query Level Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.884,\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.884,\n",
      "    \"f1_score\": 0.9384288747346072\n",
      "}\n",
      "Item Level Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.8752266956837141,\n",
      "    \"precision\": 0.9636581469648562,\n",
      "    \"recall\": 0.9051012753188297,\n",
      "    \"f1_score\": 0.9334622823984525\n",
      "}\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "you did something wrong formulating either the uri or your sparql query\n",
      "LLAMA3 metrics:\n",
      "Query Level Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.8891089108910891,\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.8891089108910891,\n",
      "    \"f1_score\": 0.9412997903563942\n",
      "}\n",
      "Item Level Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.864280652019844,\n",
      "    \"precision\": 0.9560956487651902,\n",
      "    \"recall\": 0.9,\n",
      "    \"f1_score\": 0.9272001520623456\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "GPT4O_RESULTS_PATH = os.path.join(os.getcwd(), \"data\", \"Gpt4o-qa_test_results.json\")\n",
    "QWEN_RESULTS_PATH = os.path.join(os.getcwd(), \"data\", \"Qwen2.5-3B_qa_test_results.json\")\n",
    "LLAMA3_RESULTS_PATH = os.path.join(\n",
    "    os.getcwd(), \"data\", \"Llama3.2-3B-qa_test_results.json\"\n",
    ")\n",
    "\n",
    "test_results_path = {\n",
    "    \"GPT4O\": GPT4O_RESULTS_PATH,\n",
    "    \"QWEN\": QWEN_RESULTS_PATH,\n",
    "    \"LLAMA3\": LLAMA3_RESULTS_PATH,\n",
    "}\n",
    "for model, path in test_results_path.items():\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            results = json.load(f)\n",
    "        query_level_metrics, item_level_metrics = calculate_metrics(results)\n",
    "\n",
    "        print(\n",
    "            f\"{model} metrics:\\nQuery Level Metrics:\\n{json.dumps(query_level_metrics, indent=4)}\"\n",
    "        )\n",
    "        print(f\"Item Level Metrics:\\n{json.dumps(item_level_metrics, indent=4)}\")\n",
    "\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{model} results file not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
